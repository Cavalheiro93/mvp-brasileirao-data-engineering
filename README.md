# âš½ MVP - Engenharia de Dados com Databricks, AWS e Redshift

Este projeto foi desenvolvido como parte da PÃ³s-GraduaÃ§Ã£o em Data Science e Analytics da PUC-Rio.  
O objetivo Ã© construir um pipeline completo de Engenharia de Dados usando ferramentas do mercado, com foco em dados reais do Campeonato Brasileiro SÃ©rie A 2024.

---
## ğŸ“š SumÃ¡rio

- [ğŸš€ Tecnologias Utilizadas](#-tecnologias-utilizadas)
- [ğŸ“ Estrutura de Pastas](#-estrutura-de-pastas)
- [ğŸ“’ Notebooks do Projeto](#-notebooks-do-projeto)
- [ğŸ“Œ ObservaÃ§Ãµes](#-observaÃ§Ãµes)
- [00 - ConfiguraÃ§Ã£o Inicial](notebooks/00-Configuracao.ipynb)
- <img src="images/notebook.png" width="18"/> [00 - ConfiguraÃ§Ã£o Inicial](notebooks/00-Configuracao.ipynb)


## ğŸš€ Tecnologias Utilizadas

- **Databricks Community Edition**: para ingestÃ£o, transformaÃ§Ã£o e tratamento dos dados com PySpark (ETL)
- **AWS S3**: armazenamento em Data Lake (Bronze, Silver, Gold)
- **Amazon Redshift Serverless**: utilizado como Data Warehouse para armazenar a camada Gold do projeto, estruturada em Data Marts temÃ¡ticos focados em clubes, jogadores e mÃ©tricas estatÃ­sticas.
- **PySpark + SQL**: para manipulaÃ§Ã£o, modelagem e criaÃ§Ã£o de data marts
- **GitHub**: versionamento e documentaÃ§Ã£o do projeto

---


## ğŸ“ Estrutura de Pastas

```plaintext
â”œâ”€â”€ ğŸ“ data/                â†’ ContÃ©m os dados divididos por camadas do Data Lake
â”‚   â”œâ”€â”€ ğŸ“‚ bronze/          â†’ Dados brutos, exatamente como foram recebidos (raw)
â”‚   â”œâ”€â”€ ğŸ“‚ silver/          â†’ Dados tratados, limpos e padronizados
â”‚   â””â”€â”€ ğŸ“‚ gold/            â†’ Dados modelados prontos para anÃ¡lise e consumo (Data Marts)

â”œâ”€â”€ ğŸ“ notebooks/           â†’ Notebooks com cada etapa do pipeline de dados
â”‚   â””â”€â”€ 00-Configuracao     â†’ Notebook de configuraÃ§Ã£o de ambiente e credenciais

â”œâ”€â”€ ğŸ“ images/              â†’ Diagramas, capturas de tela e elementos visuais do projeto
â”œâ”€â”€ README.md              â†’ DocumentaÃ§Ã£o geral do projeto
â””â”€â”€ placeholder.txt        â†’ Arquivo temporÃ¡rio para inicializar o repositÃ³rio
```


## ğŸ“’ Notebooks do Projeto

| Ordem | Nome do Notebook         | DescriÃ§Ã£o                                                       | Link
|-------|--------------------------|-----------------------------------------------------------------|-------|
| 00    | `00-Configuracao.ipynb`  | Leitura das credenciais, configuraÃ§Ã£o do S3 e testes de conexÃ£o |[ğŸ”—](notebooks/00-Configuracao.ipynb)


### ğŸ“Œ ObservaÃ§Ãµes
> ğŸ” **Credenciais AWS** nÃ£o estÃ£o incluÃ­das no repositÃ³rio por seguranÃ§a.  
> O arquivo `aws_credentials.json` foi usado localmente para leitura via Spark no notebook `00-Configuracao`.

---

## ğŸ§­ Etapas do Projeto

O projeto foi construÃ­do de forma sequencial, seguindo boas prÃ¡ticas de engenharia de dados. Abaixo, descrevemos cada uma das etapas realizadas:

1. ğŸ“˜ ConfiguraÃ§Ã£o Inicial | [00-ConfiguracaoğŸ“](notebooks/00-Configuracao.ipynb)

- CriaÃ§Ã£o do bucket S3 com as camadas Bronze, Silver e Gold
- DefiniÃ§Ã£o de credenciais seguras em arquivo .json
- ConfiguraÃ§Ã£o do acesso no Databricks via Spark

