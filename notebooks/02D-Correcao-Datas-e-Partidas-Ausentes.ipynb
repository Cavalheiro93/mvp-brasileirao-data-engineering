{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c8f230c3-0fe3-499e-9752-b9a97d706832",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# üìå 02D-Correcao-Datas-e-Partidas-Ausentes\n",
    "üìç Objetivo: corrigir as Datas e Partidas ausentes no banco de dados.\n",
    "\n",
    "Durante uma an√°lise explorat√≥ria dos dados, foi notado que algumas partidas estavam ausentes da base, fezendo-se necess√°rio o input manual."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e4b2e5e1-3a3a-4d12-b7bf-e786e4f56cd1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## üî∂ Cria√ß√£o dos Dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0ccbcf3c-ecbd-459e-91f3-cc2cbc113b2e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### üîπ Leitura do S3 e cria√ß√£o do Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "672570c3-7ee3-42ef-ab9e-c6ff8245efd6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Caminho correto no S3 para armazenar os arquivos\n",
    "#silver_parquet_path = \"s3://mvp-brasileirao-2024/silver/parquet/brasil_seriea_2024_todas_partidas\"\n",
    "silver_delta_path_partidas = \"s3://mvp-brasileirao-2024/silver/delta/brasil_seriea_2024_todas_partidas\"\n",
    "\n",
    "# Caminho correto no S3 para armazenar os arquivos\n",
    "#silver_parquet_path = f\"s3a://mvp-brasileirao-2024/silver/parquet/brasil_seriea_2024_estatistica_jogador\"\n",
    "silver_delta_path_estatisticas = f\"s3a://mvp-brasileirao-2024/silver/delta/brasil_seriea_2024_estatistica_jogador\"\n",
    "\n",
    "df_estatisticas = spark.read.format(\"delta\").load(silver_delta_path_estatisticas)\n",
    "df_partidas = spark.read.format(\"delta\").load(silver_delta_path_partidas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6328ce65-e6f4-4ec2-99bc-28155791b4ce",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "## üî∂ Aplicar transforma√ß√µes (limpeza e padroniza√ß√£o) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a7152ab6-ce97-4482-b8d4-f67309ec551f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### üîπ Converter a coluna \"Data\" para formato Date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d142adc6-7585-441a-beaf-458324fa36c1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import to_date, col\n",
    "\n",
    "# Converter a coluna \"Data\" para DateType no Spark\n",
    "df_partidas = df_partidas.withColumn(\"Data\", to_date(col(\"Data\")))\n",
    "df_estatisticas = df_estatisticas.withColumn(\"Data\", to_date(col(\"Data\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "49b7428b-9cbd-46b3-9337-ec920f0a17d6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### üîπ Criar a Chave √önica (Clube + Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "25919519-6ab9-40d7-89a4-c2971116f1de",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import concat_ws\n",
    "\n",
    "# Criar a chave √∫nica nos dois DataFrames\n",
    "df_estatisticas = df_estatisticas.withColumn(\"Chave\", concat_ws(\"_\", col(\"Clube\"), col(\"Data\")))\n",
    "df_partidas = df_partidas.withColumn(\"Chave\", concat_ws(\"_\", col(\"Clube\"), col(\"Data\")))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6948178f-9d2a-4c0e-a073-34e6ca57ec73",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### üîπ Encontrar registros exclusivos de cada DataFrame\n",
    "\n",
    "Identificar registros que est√£o em df_estatisticas, mas n√£o em df_partidas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "70624cf6-9725-4999-b60e-1db6f1c9d72a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+--------------------+\n|     Clube|      Data|               Chave|\n+----------+----------+--------------------+\n|Fluminense|2024-04-13|Fluminense_2024-0...|\n|Fluminense|2024-04-13|Fluminense_2024-0...|\n|Fluminense|2024-04-13|Fluminense_2024-0...|\n|Fluminense|2024-04-13|Fluminense_2024-0...|\n|Fluminense|2024-04-13|Fluminense_2024-0...|\n|Fluminense|2024-04-13|Fluminense_2024-0...|\n|Fluminense|2024-04-13|Fluminense_2024-0...|\n|Fluminense|2024-04-13|Fluminense_2024-0...|\n|Fluminense|2024-04-13|Fluminense_2024-0...|\n|Fluminense|2024-04-13|Fluminense_2024-0...|\n|Fluminense|2024-04-13|Fluminense_2024-0...|\n|Fluminense|2024-04-13|Fluminense_2024-0...|\n|Fluminense|2024-04-13|Fluminense_2024-0...|\n|Fluminense|2024-04-13|Fluminense_2024-0...|\n|Fluminense|2024-04-13|Fluminense_2024-0...|\n|Bragantino|2024-04-13|Bragantino_2024-0...|\n|Bragantino|2024-04-13|Bragantino_2024-0...|\n|Bragantino|2024-04-13|Bragantino_2024-0...|\n|Bragantino|2024-04-13|Bragantino_2024-0...|\n|Bragantino|2024-04-13|Bragantino_2024-0...|\n+----------+----------+--------------------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "df_estatisticas_unicos = df_estatisticas.join(df_partidas, \"Chave\", \"left_anti\")\n",
    "\n",
    "# Exibir resultados\n",
    "df_estatisticas_unicos.select(\"Clube\", \"Data\", \"Chave\").show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "00891168-21a2-40b6-af79-8a745860a304",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Identificar registros que est√£o em df_partidas, mas n√£o em df_estatisticas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2a0116e8-0c16-451d-b515-ef5a1053ebb6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+----------+--------------------+\n|       Clube|      Data|               Chave|\n+------------+----------+--------------------+\n| Corinthians|2024-07-02|Corinthians_2024-...|\n|   Fortaleza|2024-07-04|Fortaleza_2024-07-04|\n|   S√£o Paulo|2024-07-12|S√£o Paulo_2024-07-12|\n|   S√£o Paulo|2024-11-06|S√£o Paulo_2024-11-06|\n|      Cuiab√°|2024-09-17|   Cuiab√°_2024-09-17|\n|Athletico-PR|2024-10-18|Athletico-PR_2024...|\n|    Flamengo|2024-06-27| Flamengo_2024-06-27|\n|      Gr√™mio|2024-04-28|   Gr√™mio_2024-04-28|\n|       Bahia|2024-09-22|    Bahia_2024-09-22|\n|    Cruzeiro|2024-07-04| Cruzeiro_2024-07-04|\n+------------+----------+--------------------+\nonly showing top 10 rows\n\n"
     ]
    }
   ],
   "source": [
    "df_partidas_unicos = df_partidas.join(df_estatisticas, \"Chave\", \"left_anti\")\n",
    "\n",
    "# Exibir resultados\n",
    "df_partidas_unicos.select(\"Clube\", \"Data\", \"Chave\").show(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e028e6f0-08cd-4d04-a116-1015b0f6551f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "## üî∂ Aplicar ajuste nas datas \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ed71905d-461e-41a0-a7fa-ee112dc79bcd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### üîπ Cria coluna `Data_Original` a partir da coluna de Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b8b12ea1-433d-4151-a7df-3a5d720b383b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import date_sub\n",
    "\n",
    "# Criar a coluna \"Data Original\"\n",
    "df_partidas_unicos = df_partidas_unicos.withColumn(\"Data Original\", col(\"Data\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "30efd634-6f76-4003-84ab-bbcc3af14a27",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### üîπ Subtrai 1 dia dessa `Data_Original` para ajuste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c6828a0e-58af-497a-87d2-897b087865da",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Ajustar a data subtraindo 1 dia\n",
    "df_partidas_unicos = df_partidas_unicos.withColumn(\"Data Ajustada\", date_sub(col(\"Data\"), 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1963af90-18c9-4a2c-ab62-8c60b06a75aa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### üîπ Criando a nova coluna agora ajustada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "522352b6-5f57-4d28-9fb2-c59e5e940b01",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Criar novamente a chave ajustada\n",
    "df_partidas_unicos = df_partidas_unicos.withColumn(\"Chave Ajustada\", \n",
    "    concat_ws(\"_\", col(\"Clube\"), col(\"Data Ajustada\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c39479ca-42b6-41c6-8053-baaddce2bc27",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### üîπ Criando os Dicion√°rios com as Datas compativeis dos dois Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0af6691d-03ec-4074-bc16-db0b3801cfa0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Criar dicion√°rios para mapeamento de corre√ß√µes\n",
    "correcao_datas = dict(df_partidas_unicos.select(\"Chave\", \"Data Ajustada\").rdd.collect())\n",
    "correcao_chaves = dict(df_partidas_unicos.select(\"Chave\", \"Chave Ajustada\").rdd.collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0d241084-a058-46d6-ab4b-39a32d4db606",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### üîπ Converter os dicion√°rios em listas de tuplas para criar DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "62363986-63e1-4dd7-8c5c-f6ff0d086deb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import Row\n",
    "\n",
    "# Converter os dicion√°rios em listas de tuplas para criar DataFrames\n",
    "correcao_datas_df = spark.createDataFrame([Row(Chave=k, Data_Ajustada=v) for k, v in correcao_datas.items()])\n",
    "correcao_chaves_df = spark.createDataFrame([Row(Chave=k, Chave_Ajustada=v) for k, v in correcao_chaves.items()])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c8621ad7-8254-4fe1-92a4-d75673fc5168",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### üîπ JOIN para substituir a Data e a Chave ajustada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9b982d45-95fb-4cfe-b405-2fc8cff333f0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+-------------+--------------------+--------------------+---------------+\n|      Clube|      Data|Data Ajustada|               Chave|      Chave Ajustada| Status_Ajustes|\n+-----------+----------+-------------+--------------------+--------------------+---------------+\n|  Juventude|2024-10-26|   2024-10-26|Juventude_2024-10-26|Juventude_2024-10-26|Sem modifica√ß√£o|\n|     Cuiab√°|2024-12-05|   2024-12-05|   Cuiab√°_2024-12-05|   Cuiab√°_2024-12-05|Sem modifica√ß√£o|\n|     Cuiab√°|2024-11-02|   2024-11-02|   Cuiab√°_2024-11-02|   Cuiab√°_2024-11-02|Sem modifica√ß√£o|\n| Fluminense|2024-06-30|   2024-06-30|Fluminense_2024-0...|Fluminense_2024-0...|Sem modifica√ß√£o|\n|  Palmeiras|2024-11-04|   2024-11-04|Palmeiras_2024-11-04|Palmeiras_2024-11-04|Sem modifica√ß√£o|\n|Corinthians|2024-07-02|   2024-07-01|Corinthians_2024-...|Corinthians_2024-...|Ajustado -1 dia|\n|  S√£o Paulo|2024-10-05|   2024-10-05|S√£o Paulo_2024-10-05|S√£o Paulo_2024-10-05|Sem modifica√ß√£o|\n|  Fortaleza|2024-07-04|   2024-07-03|Fortaleza_2024-07-04|Fortaleza_2024-07-03|Ajustado -1 dia|\n|  S√£o Paulo|2024-07-12|   2024-07-11|S√£o Paulo_2024-07-12|S√£o Paulo_2024-07-11|Ajustado -1 dia|\n|     Gr√™mio|2024-08-25|   2024-08-25|   Gr√™mio_2024-08-25|   Gr√™mio_2024-08-25|Sem modifica√ß√£o|\n+-----------+----------+-------------+--------------------+--------------------+---------------+\nonly showing top 10 rows\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import coalesce, when\n",
    "\n",
    "# Fazer o join para substituir a Data e a Chave ajustada\n",
    "df_partidas_corrigido = df_partidas.alias(\"p\") \\\n",
    "    .join(correcao_datas_df.alias(\"c\"), col(\"p.Chave\") == col(\"c.Chave\"), \"left\") \\\n",
    "    .join(correcao_chaves_df.alias(\"k\"), col(\"p.Chave\") == col(\"k.Chave\"), \"left\") \\\n",
    "    .withColumn(\"Data Ajustada\", coalesce(col(\"c.Data_Ajustada\"), col(\"p.Data\"))) \\\n",
    "    .withColumn(\"Chave Ajustada\", coalesce(col(\"k.Chave_Ajustada\"), col(\"p.Chave\"))) \\\n",
    "    .select(\"p.*\", \"Data Ajustada\", \"Chave Ajustada\")  # Manter todas as colunas originais + ajustadas\n",
    "\n",
    "# Criar a coluna \"Status_Ajustes\" com refer√™ncia correta √†s colunas\n",
    "df_partidas_corrigido = df_partidas_corrigido.withColumn(\n",
    "    \"Status_Ajustes\",\n",
    "    when(col(\"p.Chave\") == col(\"Chave Ajustada\"), \"Sem modifica√ß√£o\").otherwise(\"Ajustado -1 dia\")\n",
    ")\n",
    "\n",
    "# Exibir os ajustes aplicados\n",
    "df_partidas_corrigido.select(\"Clube\", \"Data\", \"Data Ajustada\", \"Chave\", \"Chave Ajustada\", \"Status_Ajustes\").show(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "78579ac5-f7b1-4454-baec-523b8529dc02",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### üîπ Renomeia as colunas de Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0cebab48-be0d-48ba-9ee7-7086156228e3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_partidas_corrigido = df_partidas_corrigido.drop(\"Chave\", \"Chave Ajustada\", \"Data\") \\\n",
    "    .withColumnRenamed(\"Data Ajustada\", \"Data\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e9e1394f-19bb-47f6-bbfe-1eab8d056212",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## üíæ Salvar os dados na camada Silver (Parquet no S3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "08a7c118-6767-4531-81e2-6153c1ea0b06",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### üîπ Salvando o arquivo no S3 camada Silver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f339fa09-d1c4-4917-b27f-fe2dd8805559",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Dados corrigidos e salvos na Silver sem conflitos!\n‚úÖ Dados salvos corretamente em Parquet e Delta, em pastas separadas!\n"
     ]
    }
   ],
   "source": [
    "# Caminho correto no S3 para armazenar os arquivos\n",
    "silver_parquet_path = \"s3a://mvp-brasileirao-2024/silver/parquet/brasil_seriea_2024_todas_partidas\"\n",
    "silver_delta_path = \"s3a://mvp-brasileirao-2024/silver/delta/brasil_seriea_2024_todas_partidas\"\n",
    "\n",
    "# Remover completamente o Delta anterior para evitar conflito de esquema\n",
    "#dbutils.fs.rm(silver_delta_path, recurse=True)\n",
    "\n",
    "# Salvar em Parquet (para acessibilidade geral)\n",
    "df_partidas_corrigido.write.mode(\"overwrite\").parquet(silver_parquet_path)\n",
    "\n",
    "# Salvar em Delta (agora com mergeSchema ativado)\n",
    "df_partidas_corrigido.write.format(\"delta\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .option(\"mergeSchema\", \"true\") \\\n",
    "    .save(silver_delta_path)\n",
    "\n",
    "print(\"‚úÖ Dados corrigidos e salvos na Silver sem conflitos!\")\n",
    "\n",
    "print(\"‚úÖ Dados salvos corretamente em Parquet e Delta, em pastas separadas!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bdba1218-8db2-4399-80d5-92afabefdf95",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### üîπ Salvando o arquivo no DBFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c473bde7-1381-4391-b15a-681479976a92",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Dados transformados e salvos na camada Silver no DBFS com sucesso!\n"
     ]
    }
   ],
   "source": [
    "# Caminho no DBFS para armazenar os dados Silver temporariamente\n",
    "dbfs_path_silver = \"dbfs:/mnt/silver_temp/todas_partidas\"\n",
    "\n",
    "# Salvar no DBFS em formato Parquet\n",
    "df_partidas_corrigido.write.mode(\"overwrite\").parquet(dbfs_path_silver)\n",
    "\n",
    "print(\"‚úÖ Dados transformados e salvos na camada Silver no DBFS com sucesso!\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "1"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "02D-Correcao-Datas-e-Partidas-Ausentes",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}