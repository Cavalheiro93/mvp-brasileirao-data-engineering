{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "635084a3-0ced-491b-9cd4-4d2ba2d85ede",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# üìå Estrutura do Notebook 02A-Ingestao-Bronze-TodasPartidas\n",
    "üìç Objetivo: Ler os dados da camada Bronze, aplicar transforma√ß√µes e salvar na Silver."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "4ee33179-ca41-408a-8b97-60bf4da4bda5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run \"/Users/caio.santos.cavalheiro@gmail.com/00-Configuracao\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5b11d601-3762-493c-bad9-405600b8ed0d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## üî∂ Leitura dos dados da camada Bronze "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cf907f0b-f769-4f6b-bcd6-2787d0d1d8a6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Leitura do Arquivo BrasilSerieA_2024_TodasPartidas na camada Bronze feita com sucesso \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Leitura das credenciais de forma segura pelo Spark üîê\n"
     ]
    }
   ],
   "source": [
    "# Importar bibliotecas necess√°rias\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Definir o caminho do arquivo CSV na Bronze\n",
    "csv_file_path = f\"s3a://{aws_bucket_name}/bronze/BrasilSerieA_2024_TodasPartidas.csv\"\n",
    "\n",
    "# Ler o arquivo CSV da camada Bronze\n",
    "df_bronze = spark.read.csv(csv_file_path, header=True, inferSchema=True, sep=\";\")\n",
    "\n",
    "print(f'‚úÖ Leitura do Arquivo BrasilSerieA_2024_TodasPartidas na camada Bronze feita com sucesso ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e1f5cc9f-9006-4e87-9b4e-c0e101c02602",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## üî∂ Aplicar transforma√ß√µes (limpeza e padroniza√ß√£o) \n",
    "\n",
    "Limpezas que ser√£o aplicadas no arquivo `BrasilSerieA_2024_TodasPartidas.csv`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ce2d16e0-0e08-49ee-b2b9-0877225533af",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "\n",
    "- 1Ô∏è‚É£. Remo√ß√£o de colunas que n√£o ser√£o utilizadas (Colunas com dados de ODDs)\n",
    "- 2Ô∏è‚É£. Filtragem da Temporada [`Season`] igual a **2024**\n",
    "- 3Ô∏è‚É£. Remo√ß√£o das linhas duplicadas\n",
    "- 4Ô∏è‚É£. Remo√ß√£o de valores vazios em todas as colunas\n",
    "- 5Ô∏è‚É£. Remo√ß√£o de valores vazios em linhas que n√£o tenham valor em `Home`, `Away` ou `Res`\n",
    "- 6Ô∏è‚É£. Criar `Match_ID` (Identificador √∫nico da partida)\n",
    "- 7Ô∏è‚É£. Criar `Trismestre` que ser√° usado posteriormente\n",
    "- 8Ô∏è‚É£. Criar a coluna `Turno`, para identificarmos os jogos do Primeiro e Segundo Turno\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d779f047-ffc4-4a46-bdfd-883af3b172cd",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "üîπRemovendo colunas de ODDs que n√£o entrar√£o na an√°lise"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "from pyspark.sql.functions import col, lit, concat_ws, monotonically_increasing_id, quarter, when, to_date, sum\n",
    "\n",
    "# Removendo colunas de ODDs que n√£o entrar√£o na an√°lise\n",
    "df_silver  = df_bronze[['Country', 'League', 'Season', 'Date', 'Time', 'Home', 'Away', 'HG', 'AG', 'Res']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "df2cf67b-7094-4fdc-927a-b6237e631dc6",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "üîπFiltrando somente a temporada de 2024"
    }
   },
   "outputs": [],
   "source": [
    "# Somente partidas com 'Date = 2024'\n",
    "df_silver = df_silver.filter(col(\"Season\") == 2024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "eacd5648-494a-4685-a3f8-358228eaaa20",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "üîπRemo√ß√£o de Duplicatas e colunas vazias"
    }
   },
   "outputs": [],
   "source": [
    "# 3Ô∏è‚É£. Remover duplicatas\n",
    "df_silver = df_silver.dropDuplicates()\n",
    "\n",
    "# 4Ô∏è‚É£. Remover linhas onde todas as colunas s√£o nulas (caso existam no futuro)\n",
    "df_silver = df_silver.dropna(how=\"all\")\n",
    "\n",
    "# 5Ô∏è‚É£. Remover linhas se alguma coluna essencial estiver vazia\n",
    "df_silver = df_silver.dropna(subset=[\"Home\", \"Away\", \"Res\"])  # Ajuste conforme necess√°rio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "68d0376f-19df-4cde-b5b6-ef008634be12",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "üîπCria√ß√£o das colunas Match_ID, Trimestre e Turno"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Limpeza dos Dados e cria√ß√£o as colunas 'Match_ID', 'Trimestre' e 'Turno' conclu√≠da!\n"
     ]
    }
   ],
   "source": [
    "# 6Ô∏è‚É£. Criar `Match_ID` (Identificador √∫nico da partida)\n",
    "df_silver = df_silver.withColumn(\"Match_ID\", concat_ws(\"_\", lit(\"Match\"), monotonically_increasing_id()))\n",
    "\n",
    "# 7Ô∏è‚É£. Criar a coluna Trimestre baseado na coluna Date\n",
    "df_silver = df_silver.withColumn(\"Trimestre\", quarter(col(\"Date\")))\n",
    "\n",
    "# 8Ô∏è‚É£. Criar a coluna Turno, para identificarmos os jogos do Primeiro e Segundo Turno\n",
    "# Converter a coluna Date para o formato de data (se ainda n√£o estiver)\n",
    "df_silver = df_silver.withColumn(\"Date\", to_date(col(\"Date\"), \"yyyy-MM-dd\"))\n",
    "\n",
    "# Criar a coluna 'Turno' com base na data\n",
    "df_silver = df_silver.withColumn(\"Turno\",\n",
    "                                 when(col(\"Date\") <= \"2024-08-03\", \"Primeiro Turno\")\n",
    "                                 .otherwise(\"Segundo Turno\"))\n",
    "\n",
    "print(\"‚úÖ Limpeza dos Dados e cria√ß√£o as colunas 'Match_ID', 'Trimestre' e 'Turno' conclu√≠da!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8abfa48a-994d-4153-97e6-71fb1cfb1d2b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## üî∂ Analise Geral do arquivo Tratado** (Checagem) \n",
    "\n",
    "Ap√≥s a limpeza, vamos dar uma olhada nos campos desse arquivo.\n",
    "\n",
    "- 1Ô∏è‚É£. Criar um DataFrame com a contagem de valores vazios por coluna\n",
    "- 2Ô∏è‚É£. Exibir resumo estat√≠stico das colunas + contagem de valores vazios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "13407d6b-dd12-4c02-ab22-ed9cadff9b8d",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "üîπcontagem de valores vazios por coluna"
    }
   },
   "outputs": [],
   "source": [
    "# 1Ô∏è‚É£. Criar um DataFrame com a contagem de valores vazios por coluna\n",
    "empty_counts = df_silver.select([sum(col(c).isNull().cast(\"int\")).alias(c) for c in df_silver.columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1591fb02-1c3a-435e-8c3d-6e61aeb5f749",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "üîπresumo estat√≠stico"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìå Estat√≠sticas do DataFrame:\n+-------+-------+-------+------+------------+------------+---+---+---+--------+---------+--------------+\n|summary|Country| League|Season|        Home|        Away| HG| AG|Res|Match_ID|Trimestre|         Turno|\n+-------+-------+-------+------+------------+------------+---+---+---+--------+---------+--------------+\n|  count|    380|    380|   380|         380|         380|380|380|380|     380|      380|           380|\n|    min| Brazil|Serie A|  2024|Athletico-PR|Athletico-PR|  0|  0|  A| Match_0|        2|Primeiro Turno|\n|    max| Brazil|Serie A|  2024|     Vitoria|     Vitoria|  5|  6|  H|Match_99|        4| Segundo Turno|\n+-------+-------+-------+------+------------+------------+---+---+---+--------+---------+--------------+\n\nüìå Contagem de valores vazios por coluna:\n+-------+------+------+----+----+----+----+---+---+---+--------+---------+-----+\n|Country|League|Season|Date|Time|Home|Away| HG| AG|Res|Match_ID|Trimestre|Turno|\n+-------+------+------+----+----+----+----+---+---+---+--------+---------+-----+\n|      0|     0|     0|   0|   0|   0|   0|  0|  0|  0|       0|        0|    0|\n+-------+------+------+----+----+----+----+---+---+---+--------+---------+-----+\n\n"
     ]
    }
   ],
   "source": [
    "# 2Ô∏è‚É£. Exibir resumo estat√≠stico das colunas + contagem de valores vazios\n",
    "print(\"üìå Estat√≠sticas do DataFrame:\")\n",
    "df_silver.summary(\"count\", \"min\", \"max\").show()\n",
    "\n",
    "print(\"üìå Contagem de valores vazios por coluna:\")\n",
    "empty_counts.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7d252120-76dd-4b93-81a5-d87d07ad52e4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## üî∂ Unifica√ß√£o das Colunas `Home` e `Away` em uma s√≥ (Particularidade)\n",
    "\n",
    "Essa √© uma particularidade da nossa tabela, onde precisamos unificar as Colunas `Home` e `Away`, assim como as colunas relacionadas a ela tamb√©m.\n",
    "\n",
    "A defini√ß√£o dessa padroniza√ß√£o foi feita durante o Diagrama Relacional, onde identificamos que as colunas separadas inviabilizariam nossas an√°lises\n",
    "\n",
    "- 1Ô∏è‚É£. Cria√ß√£o do Dataframe cuja coluna fosse `Home`\n",
    "- 2Ô∏è‚É£. Cria√ß√£o do Dataframe cuja coluna fosse `Away`\n",
    "- 3Ô∏è‚É£. Unifica√ß√£o dos dois Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "df557d4f-773b-4ff4-b330-9456b899387c",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "üîπCria√ß√£o do Dataframe somente com times Mandantes"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, lit\n",
    "\n",
    "# 1Ô∏è‚É£. Criar DataFrame para os times que jogaram em casa (Home)\n",
    "df_home = df_silver.withColumn(\"Clube\", col(\"Home\")) \\\n",
    "                   .withColumn(\"HomeOrAway\", lit(\"Home\")) \\\n",
    "                   .withColumn(\"Goals\", col(\"HG\")) \\\n",
    "                   .select(\"Country\", \"League\", \"Season\", \"Date\", \"Time\", \"Trimestre\", \"Turno\", \"Clube\", \"HomeOrAway\", \"Goals\", \"Res\", \"Match_ID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e04a3861-3c37-49e2-97a4-e539890d3bd1",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "üîπCria√ß√£o do Dataframe somente com times Visitantes"
    }
   },
   "outputs": [],
   "source": [
    "# 2Ô∏è‚É£. Criar DataFrame para os times que jogaram fora (Away)\n",
    "df_away = df_silver.withColumn(\"Clube\", col(\"Away\")) \\\n",
    "                   .withColumn(\"HomeOrAway\", lit(\"Away\")) \\\n",
    "                   .withColumn(\"Goals\", col(\"AG\")) \\\n",
    "                   .select(\"Country\", \"League\", \"Season\", \"Date\", \"Time\", \"Trimestre\", \"Turno\", \"Clube\", \"HomeOrAway\", \"Goals\", \"Res\", \"Match_ID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ea1a26de-db1d-47f5-a019-c3013b77975c",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "üîπUnifica√ß√£o dos dois Dataframes"
    }
   },
   "outputs": [],
   "source": [
    "# 3Ô∏è‚É£. Unir os dois DataFrames\n",
    "df_silver = df_home.union(df_away)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ac584c90-7c82-470a-bd38-bf443ae19c43",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## üî∂ Ajustes Finais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "087ec67c-6484-4572-addb-78659e266fb1",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "üîπRenomeando as colunas"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Colunas renomeadas para um formato mais leg√≠vel.\n"
     ]
    }
   ],
   "source": [
    "# Renomear colunas para um formato mais claro\n",
    "df_silver = df_silver.withColumnRenamed(\"Country\", \"Pais\") \\\n",
    "                     .withColumnRenamed(\"League\", \"Liga\") \\\n",
    "                     .withColumnRenamed(\"Season\", \"Temporada\") \\\n",
    "                     .withColumnRenamed(\"Date\", \"Data\") \\\n",
    "                     .withColumnRenamed(\"Time\", \"Horario\") \\\n",
    "                     .withColumnRenamed(\"HomeOrAway\", \"MandanteVisitante\") \\\n",
    "                     .withColumnRenamed(\"Res\", \"Resultado\")\n",
    "\n",
    "print(\"‚úÖ Colunas renomeadas para um formato mais leg√≠vel.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a45adbd7-c1da-417d-b266-e560e4904420",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "üîπSubstituindo \"Home\" por \"Mandante\" e \"Away\" por \"Visitante\" na coluna MandanteVisitante"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import when\n",
    "\n",
    "# 1Ô∏è‚É£. Substituir \"Home\" por \"Mandante\" e \"Away\" por \"Visitante\" na coluna MandanteVisitante\n",
    "df_silver = df_silver.withColumn(\"MandanteVisitante\",\n",
    "                                 when(col(\"MandanteVisitante\") == \"Home\", \"Mandante\")\n",
    "                                 .when(col(\"MandanteVisitante\") == \"Away\", \"Visitante\")\n",
    "                                 .otherwise(col(\"MandanteVisitante\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dddd068c-6cbe-4ef8-89c4-0c90919f75b8",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "üîπAtualizar a coluna Resultado conforme as regras"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Transforma√ß√µes nas colunas MandanteVisitante e Resultado conclu√≠das!\n"
     ]
    }
   ],
   "source": [
    "# 2Ô∏è‚É£. Atualizar a coluna Resultado conforme as regras\n",
    "df_silver = df_silver.withColumn(\"Resultado\",\n",
    "                                 when(col(\"Resultado\") == \"D\", \"Empate\")\n",
    "                                 .when((col(\"MandanteVisitante\") == \"Mandante\") & (col(\"Resultado\") == \"H\"), \"Vitoria\")\n",
    "                                 .when((col(\"MandanteVisitante\") == \"Visitante\") & (col(\"Resultado\") == \"A\"), \"Vitoria\")\n",
    "                                 .otherwise(\"Derrota\"))\n",
    "\n",
    "print(\"‚úÖ Transforma√ß√µes nas colunas MandanteVisitante e Resultado conclu√≠das!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b9860c30-1cff-431d-a8db-0d8481e26c09",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "üîπCria um Dicionario de `mapeamento_clubes`"
    }
   },
   "outputs": [],
   "source": [
    "# Dicion√°rio de padroniza√ß√£o dos nomes dos clubes (em ordem alfab√©tica)\n",
    "mapeamento_clubes = {\n",
    "    \"Atletico GO\": \"Atl√©tico-GO\",\n",
    "    \"Atletico-MG\": \"Atl√©tico-MG\",\n",
    "    \"Athletico-PR\": \"Athletico-PR\",\n",
    "    \"Bahia\": \"Bahia\",\n",
    "    \"Botafogo RJ\": \"Botafogo\",\n",
    "    \"Bragantino\": \"Bragantino\",\n",
    "    \"Corinthians\": \"Corinthians\",\n",
    "    \"Criciuma\": \"Crici√∫ma\",\n",
    "    \"Cruzeiro\": \"Cruzeiro\",\n",
    "    \"Cuiaba\": \"Cuiab√°\",\n",
    "    \"Flamengo RJ\": \"Flamengo\",\n",
    "    \"Fluminense\": \"Fluminense\",\n",
    "    \"Fortaleza\": \"Fortaleza\",\n",
    "    \"Gremio\": \"Gr√™mio\",\n",
    "    \"Internacional\": \"Internacional\",\n",
    "    \"Juventude\": \"Juventude\",\n",
    "    \"Palmeiras\": \"Palmeiras\",\n",
    "    \"Sao Paulo\": \"S√£o Paulo\",\n",
    "    \"Vasco\": \"Vasco da Gama\",\n",
    "    \"Vitoria\": \"EC Vit√≥ria\"\n",
    "}\n",
    "\n",
    "df_silver = df_silver.replace(mapeamento_clubes, subset=[\"Clube\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d60de395-2c9c-4945-94bc-fdfaaf9dbc0f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## üíæ Salvar os dados na camada Silver (Parquet no S3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4e27927b-9dcd-4aca-a7bf-87ca7eaf67f8",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "üîπ Salvando o arquivo no S3 camada Silver"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Dados salvos corretamente em Parquet e Delta, em pastas separadas!\n"
     ]
    }
   ],
   "source": [
    "# Caminho correto no S3 para armazenar os arquivos\n",
    "silver_parquet_path = \"s3://mvp-brasileirao-2024/silver/parquet/brasil_seriea_2024_todas_partidas\"\n",
    "silver_delta_path = \"s3://mvp-brasileirao-2024/silver/delta/brasil_seriea_2024_todas_partidas\"\n",
    "\n",
    "# Remover o Delta anterior (use com cautela)\n",
    "dbutils.fs.rm(silver_delta_path, recurse=True)\n",
    "\n",
    "# Salvar em Parquet (para acessibilidade geral)\n",
    "df_silver.write.mode(\"overwrite\").parquet(silver_parquet_path)\n",
    "\n",
    "# Salvar em Delta (para controle e governan√ßa)\n",
    "df_silver.write.format(\"delta\").mode(\"overwrite\").save(silver_delta_path)\n",
    "\n",
    "print(\"‚úÖ Dados salvos corretamente em Parquet e Delta, em pastas separadas!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d5c0dba7-881a-41a6-8ab0-dcac9bcd9c9d",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "üîπ Salvando o arquivo no DBFS"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Dados transformados e salvos na camada Silver no DBFS com sucesso!\n"
     ]
    }
   ],
   "source": [
    "# Caminho no DBFS para armazenar os dados Silver temporariamente\n",
    "dbfs_path_silver = \"dbfs:/mnt/silver_temp/todas_partidas\"\n",
    "\n",
    "# Salvar no DBFS em formato Parquet\n",
    "df_silver.write.mode(\"overwrite\").parquet(dbfs_path_silver)\n",
    "\n",
    "print(\"‚úÖ Dados transformados e salvos na camada Silver no DBFS com sucesso!\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "1"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "02A-Ingestao-Bronze-TodasPartidas",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}