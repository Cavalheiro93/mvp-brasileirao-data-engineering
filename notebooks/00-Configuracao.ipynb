{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "12fb5ddc-1594-4ccc-af3b-db98f3364287",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# üìò 00 - Configura√ß√£o do Ambiente e Credenciais\n",
    "\n",
    "Este notebook tem como objetivo realizar a configura√ß√£o inicial do projeto, incluindo:\n",
    "\n",
    "- Leitura segura das credenciais da AWS\n",
    "- Configura√ß√£o dos acessos via Spark\n",
    "- Defini√ß√£o dos caminhos das camadas Bronze, Silver e Gold no S3\n",
    "- Valida√ß√£o da conex√£o com o bucket da AWS\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8801da41-15f9-44f5-995b-779f9ca73c52",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## üîê Leitura das credenciais da AWS (de forma segura)\n",
    "\n",
    "As credenciais foram armazenadas previamente no arquivo `aws_credentials.json` no diret√≥rio `dbfs:/FileStore/tables/`. O arquivo **n√£o √© compartilhado no reposit√≥rio por seguran√ßa**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4835526a-0cc7-4294-9396-2dbd99f55b96",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Leitura das credenciais de forma segura pelo Spark üîê\n"
     ]
    }
   ],
   "source": [
    "# Ler o arquivo JSON usando Spark\n",
    "credentials_df = spark.read.option(\"multilinea\", \"true\").json(\"dbfs:/FileStore/tables/aws_credentials.json\")\n",
    "\n",
    "credentials_dict = credentials_df.collect()[0].asDict()\n",
    "\n",
    "# Definir credenciais da AWS\n",
    "aws_access_key_id = credentials_dict['aws_access_key_id']\n",
    "aws_secret_access_key = credentials_dict['aws_secret_access_key']\n",
    "\n",
    "print(f'Leitura das credenciais de forma segura pelo Spark üîê')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4a3faae7-1bdf-4971-a2a4-0cb0ea655a4a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## üì¶ Defini√ß√£o do bucket e caminhos das camadas no S3\n",
    "O nome do bucket usado no projeto √©:\n",
    "`mvp-brasileirao-2024`\n",
    "\n",
    "Os caminhos das camadas foram definidos usando o prefixo `s3a://`, que permite leitura e escrita via Spark:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f03db9c7-2dc5-4048-8bb8-dd0ccc2dc79a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caminhos definidos:\nüìÇ Bronze: s3a://mvp-brasileirao-2024/bronze/ | üìÇ Silver: s3a://mvp-brasileirao-2024/silver/ | üìÇ Gold: s3a://mvp-brasileirao-2024/gold/\n"
     ]
    }
   ],
   "source": [
    "# Definir o nome do bucket S3\n",
    "aws_bucket_name = \"mvp-brasileirao-2024\"\n",
    "\n",
    "# Definir os caminhos das camadas no S3\n",
    "bronze_path = f\"s3a://{aws_bucket_name}/bronze/\"\n",
    "silver_path = f\"s3a://{aws_bucket_name}/silver/\"\n",
    "gold_path = f\"s3a://{aws_bucket_name}/gold/\"\n",
    "\n",
    "# Exibir os caminhos para confer√™ncia\n",
    "print(\"Caminhos definidos:\")\n",
    "print(f\"üìÇ Bronze: {bronze_path} | üìÇ Silver: {silver_path} | üìÇ Gold: {gold_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2fb14850-e9bf-4a1a-b59c-2a3fade545c8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## ‚öôÔ∏è Configura√ß√£o das credenciais no Spark\n",
    "As credenciais foram configuradas como propriedades do Spark, utilizando as op√ß√µes fs.`s3a.access.key` e `fs.s3a.secret.key`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c13a0346-20b6-446f-99c5-75afb3ed9633",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Credenciais configuradas com sucesso!\n"
     ]
    }
   ],
   "source": [
    "# Configurar as credenciais no Spark\n",
    "spark.conf.set(\"fs.s3a.access.key\", aws_access_key_id)\n",
    "spark.conf.set(\"fs.s3a.secret.key\", aws_secret_access_key)\n",
    "spark.conf.set(\"fs.s3a.endpoint\", \"s3.amazonaws.com\")\n",
    "\n",
    "print(\"‚úÖ Credenciais configuradas com sucesso!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "31adef5e-ca0b-45da-9529-5f1f8da9f498",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## ‚úÖ Valida√ß√£o da Conex√£o com o S3\n",
    "Por fim, foi realizado um teste de leitura nas camadas Bronze e Silver para garantir que a conex√£o com o bucket estava funcionando corretamente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bd20aaa0-62c7-4f69-94f4-4d89f367345a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Conex√£o bem-sucedida! Arquivos encontrados na camada Bronze e Silver:\n"
     ]
    }
   ],
   "source": [
    "aws_bucket_name = \"mvp-brasileirao-2024\"\n",
    "\n",
    "# Definir o caminho da camada Bronze\n",
    "s3_path_bronze = f\"s3a://{aws_bucket_name}/bronze/\"\n",
    "s3_path_silver = f\"s3a://{aws_bucket_name}/silver/\"\n",
    "# Listar arquivos na camada Bronze\n",
    "try:\n",
    "    files_bronze = dbutils.fs.ls(s3_path_bronze)\n",
    "    files_silver = dbutils.fs.ls(s3_path_silver)\n",
    "    print(\"‚úÖ Conex√£o bem-sucedida! Arquivos encontrados na camada Bronze e Silver:\")\n",
    "    #display(files_bronze)  # Exibir os arquivos encontrados no Databricks\n",
    "    #display(files_silver)  # Exibir os arquivos encontrados no Databricks\n",
    "except Exception as e:\n",
    "    print(\"‚ùå Erro ao conectar ao S3:\", str(e))\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "1"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "00-Configuracao",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}